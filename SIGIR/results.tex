\section{Results and Discussion}
\label{sec:results_and_discussion}
The performance of the proposed model is given in Table \ref{table:network_perf}. 
We report NDCG$@$1 and NDCG$@$10 for preliminary analysis. We also train and compare 
performance of model trained on each structural element. In this work, we compare 
models trained on headings ($SEmbed_{head}$), tables ($SEmbed_{table}$), 
lists ($SEmbed_{list}$), images ($SEmbed_{img}$) and hyperlinks ($SEmbed_{link}$). 

The proposed network architecture ($SEmbed_{all}$) performs significantly better than 
SVMRank trained on letor based features 
on three datasets (2012-2014). Statistical significance was computed using a paired t-test. 
These improvements suggest the importance of structural elements in web search. 
We posit that proposed architecture infers important features for each structure element automatically 
which is captured manually in features used in SVMRank or LambdaMart. 
An interesting exploration in the future would be to train and evaluate existing 
learning-to-rank models with pre-computed embeddings learnt via $SEmbed_{all}$.

We also trained a single network for each structural element to investigate  
its relative importance in retrieving relevant documents. It is expected that 
individual structural element will not perform better than model trained on 
combination of all elements. All structural models ($SEmbed_{head}$ - $SEmbed_{img}$) 
perform significantly lower than SVMRank baseline. 
However, their performance on all datasets shows that headings are the most useful amongst 
all other elements in retrieving relevant documents. On all datasets, 
$SEmbed_{head}$ performs better other models. 
This is followed by outlinks ($SEmbed_{link}$) and images ($SEmbed_{img}$) respectively. 
Tables ($SEmbed_{table}$) and lists ($SEmbed_{list}$), however, are not as useful as we had expected.
In future, we shall investigate the differences in embeddings of each element 
to understand their behaviour and impact on query-document matching in greater depth. 



